{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6228858a-dc3a-4fc4-a7d2-166d1faacee6",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc18454e-331b-4874-a1e2-8455a9ab915b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import ntpath\n",
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import argparse as ap\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e458b3ae-f8e8-43f2-a07d-813add83cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_expr(path):\n",
    "    expr = dt.fread(path, header=True, sep='\\t', nthreads=6)\n",
    "    expr = expr.to_pandas()\n",
    "    expr.index = expr.loc[:, 'Gene']\n",
    "    del expr['Gene']\n",
    "    expr = expr.astype(float)\n",
    "    return expr\n",
    "\n",
    "def label2dic(label):\n",
    "    label_set = list(set(label))\n",
    "    dic = {}\n",
    "    for i in range(len(label_set)):\n",
    "        dic[label_set[i]] = i\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c90a241-94ab-42a9-befe-14f524756137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(Dataset):\n",
    "    def __init__(self, data, celltypes):\n",
    "        class_labels = [ct_dic[i] for i in celltypes]\n",
    "        self.class_labels = torch.as_tensor(class_labels)\n",
    "        self.expr = data.values\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.as_tensor(self.expr[:, index]), self.class_labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85cce5d1-c055-4e32-b418-6d3a896a9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, nfeatures, nct):\n",
    "        super(net, self).__init__()\n",
    "        self.nct = nct\n",
    "        self.class_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=nfeatures, out_features=250), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(), \n",
    "            nn.Linear(in_features=250, out_features=nct))\n",
    "    def forward(self, input_data):\n",
    "        class_logits = self.class_classifier(input_data)\n",
    "        class_predictions = F.softmax(class_logits, dim=1)\n",
    "        return class_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a19de5-47af-4c8f-bf58-91fdfbd1d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, celltypes, nfeatures, nct, device, lr, n_epoch):\n",
    "    network = net(nfeatures, nct).train()\n",
    "    train_data = Datasets(train_data, celltypes)\n",
    "    lr = lr\n",
    "    n_epoch = n_epoch\n",
    "    batch_size = 256\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
    "    loss_class = nn.CrossEntropyLoss()\n",
    "    network = network.to(device)\n",
    "    loss_class = loss_class.to(device)\n",
    "    train_loader = DataLoader(dataset=train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    len_train_loader = len(train_loader) \n",
    "    print('Begin training')\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        loader_iter = iter(train_loader)\n",
    "        output_temp = []\n",
    "        label_temp = []\n",
    "        for i in range(len_train_loader):\n",
    "            expr, class_label = loader_iter.next()\n",
    "            expr = expr.to(device)\n",
    "            expr = expr.float()\n",
    "            class_label = class_label.to(device)\n",
    "            class_output = network(input_data=expr)\n",
    "            err_class = loss_class(class_output, class_label)\n",
    "            output_temp.append(class_output.argmax(dim=1).cpu().numpy().tolist())\n",
    "            label_temp.append(class_label.cpu())\n",
    "        output_temp = [i for j in output_temp for i in j ]\n",
    "        label_temp = [i for j in label_temp for i in j]\n",
    "        acc = metrics.accuracy_score(label_temp, output_temp)\n",
    "        writer.add_scalar('Loss/' + 'nfeature_' + str(nfeature) + '_ncell_' + str(ncell) + '_lr_' + str(lr) + '_epoch_' + str(n_epoch), err_class, epoch)\n",
    "        writer.add_scalar('Acc/' + 'nfeature_' + str(nfeature) + '_ncell_' + str(ncell) +'_lr_' + str(lr) + '_epoch_' + str(n_epoch), acc, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        err_class.backward()\n",
    "        optimizer.step()\n",
    "    print(acc)\n",
    "    writer.close()      \n",
    "    print('Finish Training')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d633d3-5e5a-4f45-b356-bd7bcca0c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasets(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.expr = data.values\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.as_tensor(self.expr[:, index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.expr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb5b009-da60-4770-b1df-7350cefb07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_df, network, ct_dic):\n",
    "    test_dat = datasets(test_df)\n",
    "    pred_prob = []\n",
    "    ct_dic_rev = {v: k for k, v in ct_dic.items()}\n",
    "    test_loader = DataLoader(dataset=test_dat,\n",
    "                             batch_size=test_df.shape[1],\n",
    "                             shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = []\n",
    "        disease_labels = []\n",
    "        for batch in test_loader:\n",
    "            expr = batch\n",
    "            expr = expr.float()\n",
    "            expr = expr.to(device)\n",
    "            class_output = network(expr)\n",
    "            pred_labels.append(\n",
    "                class_output.argmax(dim=1).cpu().numpy().tolist())\n",
    "            pred_prob.append(F.softmax(class_output,dim=1).cpu().numpy())\n",
    "        pred_labels = [ct_dic_rev[i] for item in pred_labels for i in item]\n",
    "        pred_prob = pd.DataFrame(reduce(pd.concat, pred_prob))\n",
    "        pred_prob.index = test_df.columns\n",
    "        pred_prob.columns = ct_dic.keys()\n",
    "        return pred_labels, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcdc156a-2888-4399-b626-bb6aa6f757ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2000/2000 [14:44<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819196428571428\n",
      "Finish Training\n",
      "Begin training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4000/4000 [5:30:06<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9522792022792023\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "nfeatures = [1000]\n",
    "ncells = [100,1000]\n",
    "device = torch.device('cuda:1')\n",
    "lr = 0.0005\n",
    "\n",
    "for nfeature in nfeatures:\n",
    "    for ncell in ncells:\n",
    "        if ncell==1000:\n",
    "            n_epoch = 4000\n",
    "        else:\n",
    "            n_epoch = 2000 \n",
    "        train_data = read_expr('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/train.txt')\n",
    "        cts = pd.read_csv('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/ct.txt', header=None)\n",
    "        cts = cts.iloc[:,0].to_numpy()\n",
    "        ct_dic = label2dic(cts)\n",
    "        nfeatures, nct = train_data.shape[0], len(ct_dic)\n",
    "        writer = SummaryWriter('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/')\n",
    "        network = train(train_data, cts, nfeatures, nct, device, lr, n_epoch)\n",
    "        torch.save(network, '/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/' + 'lr_' + str(lr) + '_epoch_' + str(n_epoch) + '.pt')  \n",
    "        test_data = read_expr('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/expr.txt')\n",
    "        pred_labels, pred_prob = test(test_data, network, ct_dic)\n",
    "        pd.DataFrame(pred_labels).to_csv('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/' +  'pred_labels.txt',index=False)\n",
    "        pd.DataFrame(pred_prob).to_csv('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/' + 'pred_prob.txt',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd107920-4537-478b-a53f-90fbe3050143",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ee7f13-ee4b-4048-a8d3-4686f2135e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import ntpath\n",
    "import datatable as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import argparse as ap\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009673b2-29a1-4f9b-a8fc-fab2337c2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_expr(path):\n",
    "    expr = dt.fread(path, header=True, sep='\\t', nthreads=6)\n",
    "    expr = expr.to_pandas()\n",
    "    expr.index = expr.loc[:, 'Gene']\n",
    "    del expr['Gene']\n",
    "    expr = expr.astype(float)\n",
    "    return expr\n",
    "\n",
    "def label2dic(label):\n",
    "    label_set = list(set(label))\n",
    "    dic = {}\n",
    "    for i in range(len(label_set)):\n",
    "        dic[label_set[i]] = i\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101a13f9-70c0-471b-bda4-464517e2f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(Dataset):\n",
    "    def __init__(self, data, celltypes):\n",
    "        class_labels = [ct_dic[i] for i in celltypes]\n",
    "        self.class_labels = torch.as_tensor(class_labels)\n",
    "        self.expr = data.values\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.as_tensor(self.expr[:, index]), self.class_labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe303009-7b91-47cc-a9c2-67f1056b9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, nfeatures, nct):\n",
    "        super(net, self).__init__()\n",
    "        self.nct = nct\n",
    "        self.class_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=nfeatures, out_features=1000), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(), \n",
    "            nn.Linear(in_features=1000, out_features=nct))\n",
    "    def forward(self, input_data):\n",
    "        class_logits = self.class_classifier(input_data)\n",
    "        class_predictions = F.softmax(class_logits, dim=1)\n",
    "        return class_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693c8244-4384-4534-8ffc-349a8584f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, celltypes, nfeatures, nct, device, lr, n_epoch):\n",
    "    network = net(nfeatures, nct).train()\n",
    "    train_data = Datasets(train_data, celltypes)\n",
    "    lr = lr\n",
    "    n_epoch = n_epoch\n",
    "    batch_size = 256\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
    "    loss_class = nn.CrossEntropyLoss()\n",
    "    network = network.to(device)\n",
    "    loss_class = loss_class.to(device)\n",
    "    train_loader = DataLoader(dataset=train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    len_train_loader = len(train_loader) \n",
    "    print('Begin training')\n",
    "    for epoch in tqdm(range(n_epoch)):\n",
    "        loader_iter = iter(train_loader)\n",
    "        output_temp = []\n",
    "        label_temp = []\n",
    "        for i in range(len_train_loader):\n",
    "            expr, class_label = loader_iter.next()\n",
    "            expr = expr.to(device)\n",
    "            expr = expr.float()\n",
    "            class_label = class_label.to(device)\n",
    "            class_output = network(input_data=expr)\n",
    "            err_class = loss_class(class_output, class_label)\n",
    "            output_temp.append(class_output.argmax(dim=1).cpu().numpy().tolist())\n",
    "            label_temp.append(class_label.cpu())\n",
    "        output_temp = [i for j in output_temp for i in j ]\n",
    "        label_temp = [i for j in label_temp for i in j]\n",
    "        acc = metrics.accuracy_score(label_temp, output_temp)\n",
    "        writer.add_scalar('Loss/' + 'nfeature_' + str(nfeature) + '_ncell_' + str(ncell) + '_lr_' + str(lr) + '_epoch_' + str(n_epoch), err_class, epoch)\n",
    "        writer.add_scalar('Acc/' + 'nfeature_' + str(nfeature) + '_ncell_' + str(ncell) +'_lr_' + str(lr) + '_epoch_' + str(n_epoch), acc, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        err_class.backward()\n",
    "        optimizer.step()\n",
    "    print(acc)\n",
    "    writer.close()      \n",
    "    print('Finish Training')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1ab299-5fb9-4170-b41f-1997fca0d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasets(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.expr = data.values\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.as_tensor(self.expr[:, index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.expr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab971e13-9b6d-4b62-b103-2d98772f8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_df, network, ct_dic):\n",
    "    test_dat = datasets(test_df)\n",
    "    pred_prob = []\n",
    "    ct_dic_rev = {v: k for k, v in ct_dic.items()}\n",
    "    test_loader = DataLoader(dataset=test_dat,\n",
    "                             batch_size=test_df.shape[1],\n",
    "                             shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = []\n",
    "        disease_labels = []\n",
    "        for batch in test_loader:\n",
    "            expr = batch\n",
    "            expr = expr.float()\n",
    "            expr = expr.to(device)\n",
    "            class_output = network(expr)\n",
    "            pred_labels.append(\n",
    "                class_output.argmax(dim=1).cpu().numpy().tolist())\n",
    "            pred_prob.append(F.softmax(class_output,dim=1).cpu().numpy())\n",
    "        pred_labels = [ct_dic_rev[i] for item in pred_labels for i in item]\n",
    "        pred_prob = pd.DataFrame(reduce(pd.concat, pred_prob))\n",
    "        pred_prob.index = test_df.columns\n",
    "        pred_prob.columns = ct_dic.keys()\n",
    "        return pred_labels, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72cffba6-9996-411a-a8a2-a67079297636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [16:55<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986607142857142\n",
      "Finish Training\n",
      "Begin training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3000/3000 [9:55:46<00:00, 11.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821269586894587\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "nfeatures = [10000]\n",
    "ncells = [100,1000]\n",
    "device = torch.device('cuda:1')\n",
    "lr = 0.0005\n",
    "\n",
    "for nfeature in nfeatures:\n",
    "    for ncell in ncells:\n",
    "        if ncell == 100:\n",
    "            n_epoch = 1000\n",
    "        else:\n",
    "            n_epoch = 3000\n",
    "        train_data = read_expr('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/train.txt')\n",
    "        cts = pd.read_csv('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/ct.txt', header=None)\n",
    "        cts = cts.iloc[:,0].to_numpy()\n",
    "        ct_dic = label2dic(cts)\n",
    "        nfeatures, nct = train_data.shape[0], len(ct_dic)\n",
    "        writer = SummaryWriter('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/')\n",
    "        network = train(train_data, cts, nfeatures, nct, device, lr, n_epoch)\n",
    "        torch.save(network, '/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/' + 'lr_' + str(lr) + '_epoch_' + str(n_epoch) + '.pt')  \n",
    "        test_data = read_expr('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/expr.txt')\n",
    "        pred_labels, pred_prob = test(test_data, network, ct_dic)\n",
    "        pd.DataFrame(pred_labels).to_csv('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/' +  'pred_labels.txt',index=False)\n",
    "        pd.DataFrame(pred_prob).to_csv('/home/renpf/HPV/res/doublet/nn/' + str(nfeature) + '_' + str(ncell) + '/' + 'pred_prob.txt',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selina_py",
   "language": "python",
   "name": "selina_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
